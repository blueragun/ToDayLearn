# 머신러닝 방법론

1. 지도학습(Supervised Learning) : 훈련용 데이터에서, 여러 특성변수를 이용하여 목표변수인 라벨을 예측하도록 모델을 학습
   - 회귀(regression) : 라벨의 데이터 타입에 따라 라벨이 연속형
   - 분류(classification) : 라벨이 범주형
   - 대표알고리즘 : Linear Regression, K-nearest Neighbors, Logistic regression, Decision Tree, SVM, Random Forest, Neural Network, Deep Learning
2. 비지도학습(Unsupervised Learning) : 라벨이 없는 훈련용 데이터에서 특징 변수들 간의 관계나 유사성을 기반으로 의미있는 패턴 추출 / 자율학습
   - 군집화(Clustering)
     - 그래프상 비슷한 지점의 공통적인 요소를 보이는 것을 묶음
   - 차원축소(Dimension reduction)
     - 넓은 표본을 줄여 차원을 줄임
   - 추천시스템(Recommendation)
     - 도서를 구매하면 그 책을 구매한 사람들이 구매했던 책을 추천
   - 대표알고리즘 : k-means Clustering, Hierarchical Clustering, PCA 등
3. 강화학습(Reinforcement Learning)
   - 행동하는 주체가 있고 행동을 했을 때의 상태와 보상을 바꿔주는 환경
   - 주치가 매번 어떠한 행동을 하면 환경에 의해 상태와 보상이 바뀌면서 주체는 보상이 가장 커지는 방향으로 계속 학습해 나감
   - 대표적인 알고리즘 : SARSA, Q-Learning

# 머신러닝 모델의 분석

1. 모델 기반 지도학습 알고리즘의 일반적인 분석절차
   1. 주어진 데이터 전처리 및 탐색
   2. 적절한 모델을 선택
   3. 주어진 데이터로 모델을 훈련시킴
   4. 훈련된 모델을 적용하여 새로운 데이터에 대한 예측을 수행
2. 과대적합(Overfitting) 문제
   - 주어진 자료는 거의 완벽한 예측이 가능하나 미래의 새로운 자료에 대한 예측력이 떨어지는 문제
   - 복잡한 알고리즘을 사용하려 데이터를 훈련하는 경우, 과대적합 문제를 항상 염두해야함
3. 모델의 검증 및 평가 개요
   - 모델의 평가의 필요성
     - 과대적합을 막고 일반화 오차를 줄이기 위해서는, 새로운 데이터에 얼마나 잘 일반화될지를 파악해야함
     - 모델 적합에 사용된 자료를 평가를 위해 재활용하지 않고 평가만을 위한 데이터를 확보할 필요가 있음
4. Hold-out 방식
   - 주어진 자료를 Training, Validation, Test로 세그룹으로 랜덤하게 분할한 뒤, 주어진 목적에 따라 각각 모델의 훈련, 검증, 평가에 활용함
     - 훈련 데이터(Traning data) : 모델의 학습을 위해 사용되는 자료
       - train 80%(trian 60%, validation 20%), test 20%
       - 자동차의 연식, 마모정도, 주행거리 등이 주어지면 그 자동차의 가격을 예측하는 함수를 찾는 자료 
     - 검증 데이터(Validation data) : 훈련 자료로 적합되는 모델을 최적의 성능으로 튜닝하기 위해 사용되는 자료
       - 훈련에 필요한 하이퍼파라미터를 조정하거나, 변수선택 등에 이용
       - 모델을 훈련하기 전에 사전에 주어지는 파라미터 / 학습은 하지 않지만 이값으로 인해서 모델의 성능이 달라질 수 있음
     - 평가 데이터(Test data) : 훈련 및 검증 자료로 적합된 최종 모형이 미래에 주어질 새로운 자료에 대하여 얼마나 좋은 성과를 갖는지를 평가하는데 사용되는 자료
5. K-fold 교차 검증(cross-validation) 방식
   - 자료 수가 충분하지 않는 경우에는 훈련 데이터에서 너무 많은 양의 데이터를 검증 또는 평가 데이터에 뺏기지 않도록 교차 검증 기법을 사용
   - 자료를 균등하게 k개의 그룹으로 분할
   - 각 j에 대해 j번째 그룹을 제외한 나머지 k-1개 그룹의 자료를 이용하여 모델에 적합
   - j번째 그룹의 자료에 적합된 모델을 적용한 뒤 예측 오차를 구함
   - j=1, ..., k에 대하여 위의 과정을 반복한 뒤, k 개의 예측 오차의 평균을 구함
   - 예측 오차의 평균값을 기준으로, 모델의 검증 도는 평가를 수행
6. 편향-분산 트레이드 오프(Bias-Variance Trade off)
   - 모델의 복잡한 정도에 따라 훈련 데이터와 평가 데이터의 예측 오차는 일반적으로 아래 와 같은 패턴을 보임
     - 과대적합 : 모델복잡도가 높을수록 prediction error가 높아진다
     - 과소적합 : 모델복잡도가 높을수록 prediction error가 낮아진다
     - 모델복잡도가 높다 : Low Bias / High Variance
     - 모델복잡도가 낮다 : High Bias / Low Variance
7. 과대적합(overfitting)을 막기 위한 방법
   - 훈련 데이터를 많이 확보
   - 모델의 복잡도를 낮춤
     - 특성변수의 수를 줄이거나 차원축소
     - 파라미터에 규제를 적용