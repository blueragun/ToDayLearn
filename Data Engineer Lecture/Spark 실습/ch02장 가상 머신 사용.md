# 가상머신 사용

- 가상머신 시작

```cmd
vagrant up
```

- 가성머신 종료

```cmd
vagrant halt
```



- Putty를 이용해 가상 머신의 IP주소(192.168.10.2)로 접속  // 가상머신을 작동시켜놓아야함
- 가상 머신 접속

```cmd
vagrant ssh -- -I spark
```

- 깃 허브 저장소 복제

  -  홈디렉토리 아래 first-edition 폴더 생성

  ```cmd
  git clone https://github.com/spark-in-action/first-edition
  ```

-  스파크 셀 시작(스칼라)

```spark
spark-shell
```

- 스칼라 셀 종료

```spark
:quit
```

# RDD의 개념

- RDD 성질

  - 불변성 : 읽기 전용(read-only)  //   생성된 RDD는 절대 바뀌지 않는다
  - 복원성 : 장애 내성 // 데이터셋 자체를 중복 저장하지 않는 대신 데이터셋을 만드는데 사용된 변환 연산자 로그(즉, 데이터셋을 어떻게 만들었는지)를 남기는 방식으로 장애 내성 제공
    - 일부 노드에 장애가 발생하면 스파크는 해당 노드가 가진 데이터셋만 다시 계산해 RDD를 복원
  - 분산 : 노드 한개 이상에 저장된 데이터셋

- RDD 연산자

  - 변환 연산자 : RDD 데이터를 조작해 새로운 RDD 생성

    - filter : 조건에 따라 RDD 일부 요소 제거

    - map : 원본 RDD의 각 요소를 바꾸고 바꾼 요소로 새로운 RDD 생성

      - ```spark
        val AAA = bbb.map(_.tpString.reverse)
        ```

      - ```spark
        val AAA = bbb.map(num = num * num)
        ```

    - distinct : 중복요소를 제거한 새로운 RDD 반환

      - ```spark
        val AAA = bbb.distinct
        ```

    - flatmap : map과 동일하나 익명함수가 반환한 배열의 중첩 구조를 한단계 제거하고 모든 배열의 요소를 단일 컬렉션으로 병합

      - ```spark
        val AAA = bbb.flatMap(_.split(","))
        ```

  - 행동 연산자 : 연산자를 호출한 프로그램으로 계산 결과를 반환하거나 RDD 요소에 특정 작업을 수행하려고 실제 계산을 시작하는 역할을 한다.

    - count : 결과 값을 계산해서 반환
    - foreach