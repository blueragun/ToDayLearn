# Spark

- 아파치 스파크는 하둡의 맵리듀스를 빠르게 대처하는 빅데이터 처리 플랫폼

  - 아파치 하둡은 분산 컴퓨팅용 자바 기반 오픈소스 프레임워크 HDFS 와 맵리듀스 처리엔진으로 구성

- 파이썬, 자바, 스칼라, R언어까지 지원함

- 하둡보다 10~100배 빠름,  메모리 효율적 사용

  - 하둡의 장점 
    - 병렬처리
    - 데이터 분산
    - 장애 내성
  - 맵리듀스의 한계로 인해 스파크 탄생
    - 맵리듀스 결과를 HDFS에 저장해야 하기에 번거로움
    - 사용환경이 복잡함

- 일괄처리 기능, 실시간 데이터처리 기능, SQL과 같은 정형데이터 처리 기능, 그래프 알고리즘, 머신 러닝 알고리즘을 모두 단일 프레임워크와 통합

- 처리 시간에 약간의 오버헤드 발생, 대량의 데이터에선 좋지만 단일 환경에서도 처리가 가능하다면 효율이 떨어짐

- 온라인 트랜잭션 처리(OLTP)는 처리 불가

  - 대량의 원자성 트랜잭션을 빠르게 처리해야하는 작업에는 적합하지 않음

- 일괄 처리 작업이나 데이터 마이닝 같은 온라인 분석처리(OLAP) 에 적합

- 맵리듀스처럼 필요 Data를 디스크에 매번 가져오지 않고 메모리 캐시로 저장하는 In-Memory 실행 모델임

  

## Spark를 구성하는 컴포넌트

- 스파크 코어 : 스파크 잡과 다른 스파크 컴포넌트에 필요한 기본 기능 제공

  - RDD(Resilient Distributed Dataset) 

    1. 분산 데이터 컬렌션(즉, 데이터셋)을 추상화한 객체임, 데이터셋에 적용할 수 있는 연산 및 변환 메서드를      함께 제공

    2. 노드에 장애가 발생해도 데이터 셋을 재구성할 수 있는 '복원성' 가짐
    3. HDFS에 있는 데이터를 RAM으로 가지고 옮, RAM에 저장된 각 블록(파티션)이 바로 RDD가 참조하는 분산 컬렉션

- 스파크 SQL

  1. SQL을 사용해 대규모 분산 정형 데이터를 다룰 수 있는 기능 제공

  2. DataFrame, Dataset에 적용된 연산을 일정 시점에 RDD 연산으로 변환해 일반 스파크 잡으로 실행

  3. 외부 시스템(???)은 JDBC(Java DataBase Connect), ODBC(Open DataBase Connect) 프로토콜을 이용해 스파크 SQL 쿼리를 실행
     - 외부시스템 : TCP/IP, 카프카, 플럼, 트위터, 아마존 Kinesis

- 스파크 스트리밍

  1. 다양한 데이터 소스에서 유입되는 실시간 스트리밍 데이터를 처리하는 ''프레임워크''

  2. HDFS, 카프카, 플럼, 트위터, ZeroMQ 지원

  3. 장애가 발생하면 연산 결과를 자동으로 복구

  4. 스파크 스트리밍과 다른 스파크 컴포넌트를 단일 프로그램에서 사용해 실시간 처리 연산과 머신러닝 작업, SQL 연산, 그래프 연산 통합 가능

- 스파크 GraphX

- 스파크 MLlib : 머신러닝 알고리즘 라이브러리, 로지스틱 회귀, 의사결정 트리, 서포트 벡터 머신, 선형 회귀, 군집화 지원

