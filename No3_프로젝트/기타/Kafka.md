# Kafka

- 프로듀서 : 큐에 데이터를 넣는 역할
  - ack를 1 이상으로 설정하여, 데이터가 잘 들어갔는지 확인해야함(단, 복제도 이루어졌는지는 모름)
  - ack를 all로 한다면 복제여부도 응답받을 수 있음  // 단 속도가 느림

- 컨슈머 : 큐에서 데이터를 가져가는 역할
  - 가장 오래된 순서대로 토픽에 있는 데이터를 가져감(FIFO)
  - consumer lag
    - 프로듀서가 데이터를 놓는 속도가 컨슈머가 데이터를 가져가는 속도보다 빠르게 되면
      - 각 데이터에 붙은 offset 수가 다르게 된다(프로튜서 넣은 오프셋, 컨슈머가 읽은 오프셋)
      - 이 숫자의 차이가 lag임
      - 보통 컨슈머의 상태를 보기 위해 사용
      - 모니터링 : Burrow 
        - 멀티 카프카 클러스터 지원
        - 슬라이딩 윈도우를 통한 컨슈머의 상태를 확인할 수 있음
        - HTTP api제공

- 토픽 : 큐 / 파일시스템의 폴터, DB의 테이블과 비슷

  - 목적에 따라 이름을 다르게 가질 수 있음 / 유지보수에 수월

  - 여러개의 파티션으로 구성

  - 내부에 순서대로 데이터가 쌓임

  - 컨슈머가 데이터를 가져가더라도 데이터는 삭제되지 않음
    - 다른 그룹의 컨슈머가 붙는다면 동일 데이터를  또 가져갈 수 있음(단, auto.offset.reset = earliest 일 경우) 
    - 이것이 카프카를 사용하는 주 이유

  - 파티션이 두개이상인 경우
    - 만약 데이터가 들어왔을때 키가 null일 경우 라운드로빈으로 할당
      - 파티션 0, 파티션 1이 있을경우 데이터 7, 8, 9가 들어왔을때 앞 데이터가 0에 들어가있다면 7은 파티션 1에, 8은 파티션 0에 들어간다.
    - 키가 있을경우 키의 해시를 확인해 특정 파티션에 할당

  - 파티션을 늘리게 되면 데이터를 분산처리 할 수 있음 단, 파티션을 없앨 수 없다

    

- broker : 카프카가 설치되어 있는 서버단위(3개이상의 브로커로 구성)

  - 파티션이 1개이고 replicaiton 이 1인 토픽이 존재하고 브로커가 3대라면 3대 중 1대에 해당 토픽 정보가 저장됨

  - replication이 1이면 파티션이 1개 존재한다는 것이고 2라면 파티션은 원본 1개, 사본 1개로 존재

  - replication이 3이면 파티션 원본 1개와 복제본 2개

  - 단, 브로커의 갯수에 따라 replication 갯수가 제한됨(브로커 3, replication 4 는 될 수 없다)

    - 원본 : leader 파티션, 사본 : Follower 파티션

    - leader, Follower 파티션을 합쳐 In Sync Relica 즉, ISR이라고 볼 수 있음

      

- replication(복제 / 가용성 보장)

  - 일부 브로커가 사용불가가 되도 데이터 복제가 존재하기에 복구 가능

    

- ISR : leader, Follower 파티션을 합쳐 In Sync Relica 즉, ISR이라고 볼 수 있음

- 파티셔너 : 데이터를 토픽의 어떤 파티셔너에 넣을지 결정함

  - 레코드에 포함된 메시지 키 또는 메시지 값에 따라서 파티션의 위치 결정

  - 커스텀 파티셔너도 만들 수 있음 / 데이터 지정 가능

    

- 카프카, 레빗엠큐, 레디스큐 의 차이

  - 메시지 브로커는 이벤트브로커로 역할을 할 수 없음  // 레빗엠큐, 레디스 큐
    - 큐에 데이터를 보내고 받는 프로듀서와 컨슈머를 통해 메시지를 통신하고 네트워크를 맺는 용도
    - 메시지를 받아 적절히 처리하고 나면 즉시 또는 짧은 시간내 삭제됨
    - 즉, 메시지를 보내고 처리하고 삭제한다.
  - 이벤트 브로커는 메시지 브로커의 역할을 할 수 있음 // 카프카, AWS 키네시스
    -  이벤트 또는 메시지 레코드를 장부를 하나만 보관하고 인덱스를 통해 개별 액세스를 관리 
    - 업무상 필요한 시간동안 이벤트를 보존
    - 즉, 삭제하지 않는다 / 장애 발생시 일어난 시점부터 재처리 가능, 많은 양의 데이터를 처리할 수 있음

- 설치

  - 카프카 : wget 카프카 다운로드, tar xvf로 압축해제, 브로커 설정,  브로커 id를 각 서벼별  다른 숫자로 설정
    -  listener, advertise listener 설정
    - 주키퍼의 hostname, port번호 넣기
    - 카프카 실행, 테스트_log 토픽만들어 테스트
  - 주키퍼 : 서버 푸티 창에서 wget 으로 주키퍼 다운로드, tar xvf로 압축해제 / 서버에 주키퍼 설정(앙상블 설정), ip가 아닌 host로 통신하기위해 etc/hosts 수정
    - 카프카 통신을 위해 AWS 방화벽 설정(포트 번호 anywhere로 open)
  - 카프카 라이브러리(그래들, 레이븐)를 사용해 프로듀서와 컨슈머 사용
    - 클라이언트를 디펜던시로 할 경우 브로커, 클라이언트의 버전에 주의해야 한다.
  - 프로듀서 설정
    - 자바스크립트 프로퍼티스 콘피그를 이용해 부트스트랩 서버 설정을 로컬호스트의 카프카를 바라보도록 설정
      - 2개 이상의 ip와 포트를 설정 권장, 가용성을 위함
      - 키 시리얼 라이즈, 발유 시리얼 라이즈 사용해 직렬화 설정
    - 카프카프로듀스 클래스를 통해 이전에 선언한 설정들을 매개변수로 해서 프로듀스 인스턴스 생성
    - 키와 발유에 지정된 파티션에 맞게 저장되지만 만약 파티션이 추가될 경우 지정이 깨지기에 라우드로빈으로 전환되어 자료가 저장된다
  - 컨슈머 설정
    - 데이터를 가져오는 것은 폴링이라고 한다.
    - 파티션 오프셋 위치기록( commit)
    - 컨슈머 그룹을 통해 병렬처리
    - 동일하게 버전 주의
    - 자바스크립트 프로퍼티스 콘피그를 이용해 부트스트랩 서버 설정을 로컬호스트의 카프카를 바라보도록 설정
      - 2개 이상의 ip와 포트를 설정 권장, 가용성을 위함
      - 그룹 ip 지정
      - 키 시리얼 라이즈, 발유 시리얼 라이즈 사용해 직렬화 설정
    - 카프카컨슈머 클래스를 통해 이전에 선언한 설정들을 매개변수로 해서 컨슈머 인스턴스 생성
    - 컨슈머 그룹 정하기(토픽 지정 /subscribe() 매서드 사용)
      - 특성 파티션의 데이터를 가져오고 싶다면 assign() 매서드 사용(단, 키가 지정되어 있는 경우)
      - poll() 매서드를 통한 데이터를 가져오기 / 폴링 루프  매우중요
      - 오프셋은 컨슈머가 토픽 데이터를 어디까지 읽었는지를 확인함
      - 컨슈머 그룹이 동일한 파티션을 읽고 있더라고 그룹별로 오프셋을 달리 저장하기에 문제없다
    - 커넥터, 커넥트(깃 오픈소스가 많음)
      - 파이프라인 반복 생성 가능
    - 컴플런트의 사스 카프카 플렛폼

